
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, Add, Attention
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

def preprocess_and_merge(file_paths):
    dfs = []
    for path in file_paths:
        df = pd.read_csv(path)
        df = df[['date', 'time', 'status', 'current', 'turnover']].copy()
        df['timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'])
        df = df.sort_values('timestamp').drop(['date', 'time'], axis=1)
        dfs.append(df.set_index('timestamp'))

    merged = pd.concat(dfs, axis=1, keys=[f'idx{i}' for i in range(len(dfs))])
    merged = merged.ffill().bfill().dropna()
    return merged

def create_sequences(data, target_idx, seq_length=150):
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data)

    X, y = [], []
    for i in range(len(data_scaled) - seq_length):
        X.append(data_scaled[i:i+seq_length])
        y.append(data_scaled[i+seq_length, target_idx])
    return np.array(X), np.array(y), scaler

def build_model(input_shape):
    inp = Input(shape=input_shape)

    x1 = LSTM(64, return_sequences=True)(inp)
    x1 = BatchNormalization()(x1)
    x1 = Dropout(0.3)(x1)

    x2 = LSTM(64, return_sequences=True)(x1)
    x2 = BatchNormalization()(x2)
    x2 = Dropout(0.3)(x2)

    att = Attention()([x2, x2])
    x = Add()([att, x2])

    x = LSTM(32)(x)
    x = Dropout(0.2)(x)

    out = Dense(1)(x)

    model = Model(inputs=inp, outputs=out)
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

def main():
    # Replace with your actual file paths
    file_paths = [
        'hang_seng_index.csv',
        'hang_seng_china_a_top_100.csv',
        'hang_seng_futures.csv',
        'hang_seng_volatility.csv'
    ]

    print("Loading and preprocessing data...")
    merged = preprocess_and_merge(file_paths)
    target_idx = merged.columns.get_loc(('idx0', 'current'))

    print("Creating sequences...")
    X, y, scaler = create_sequences(merged, target_idx=target_idx)
    X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=False, test_size=0.2)

    print("Building model...")
    model = build_model(input_shape=X.shape[1:])

    print("Training model...")
    model.fit(X_train, y_train,
              validation_data=(X_val, y_val),
              epochs=100,
              batch_size=128,
              callbacks=[
                  EarlyStopping(patience=10, restore_best_weights=True),
                  ReduceLROnPlateau(patience=5)
              ])

    print("Model training complete.")

if __name__ == "__main__":
    main()